1-embed:
  dataset: 'R1'
  batch_size: 100
  output: './1-output.pt'
2-aflite:
  phi: './1-output.pt'  # input data path, must be loadable by torch.load
  L: 'LinearSGD' # SVM or LinearSGD. SVM is very slow.
  m: 128 # m means to try hypothesis on the training set, it must be large enough e.g. 10 or 64 to make AFLite not filtering out good data.
  t: 1000 # training set size for each way of partitioning
  tau: 0.85 # 0 will make the termination condition totally up to n
  k: 100 # k controlls the speed of the reduction
  n: 10000 # 0 will make the termination condition totally up to tau
  output: './2-output.pt'  # output data path, it is loadable by torch.load
3-train:
  input: './2-output.pt'
  dataset: 'R1'